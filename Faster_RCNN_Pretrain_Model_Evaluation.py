# -*- coding: utf-8 -*-
"""RCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jFpMGGEC3TJlfkP9rkfUUduYuVLLz0PV

#Set up
"""

!pip install ultralytics
!pip install -U ipywidgets

from google.colab import drive
drive.mount('/content/gdrive/')

import os
import random

import cv2

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image

"""#Data Visualization"""

traffic_map = {
    0: 'ambulance', 1: 'army vehicle', 2: 'auto rickshaw', 3: 'bicycle', 4: 'bus', 5: 'car',
    6: 'garbage van', 7: 'human hauler', 8: 'minibus', 9: 'minivan', 10: 'motorbike',
    11: 'pickup', 12: 'police car', 13: 'rickshaw', 14: 'scooter', 15: 'suv',
    16: 'taxi', 17: 'three wheelers (CNG)', 18: 'truck', 19: 'van', 20: 'wheelbarrow'
}

def load_labels(image_file, train_labels):
    label_file = os.path.splitext(image_file)[0] + ".txt"
    label_path = os.path.join(train_labels, label_file)

    with open(label_path, "r") as f:
        labels = f.read().strip().split("\n")

    return labels

def plot_object_detections(ax, image, labels):
    for label in labels:
        if len(label.split()) != 5:
            continue
        class_id, x_center, y_center, width, height = map(float, label.split())
        x_min = int((x_center - width/2) * image.shape[1])
        y_min = int((y_center - height/2) * image.shape[0])
        x_max = int((x_center + width/2) * image.shape[1])
        y_max = int((y_center + height/2) * image.shape[0])
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)
        label_name = traffic_map.get(class_id, "Unknown")
        ax.text(x_min, y_min - 10, label_name, va='bottom', color='white', backgroundcolor='red')

    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    ax.axis('off')


# Set paths
train_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/train/images"
train_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/train/labels"

# Get a list of all the image files in the training images directory
image_files = os.listdir(train_images)

# Choose 16 random image files from the list
random_images = random.sample(image_files, 16)

# Set up the plot
fig, axs = plt.subplots(4, 4, figsize=(16, 16))

# Loop over the random images and plot the object detections
for i, image_file in enumerate(random_images):
    row, col = divmod(i, 4)

    # Load the image
    image_path = os.path.join(train_images, image_file)
    image = cv2.imread(image_path)

    # Load the labels for this image
    labels = load_labels(image_file, train_labels)

    # Plot object detections
    plot_object_detections(axs[row, col], image, labels)

plt.show()

"""#Try pre-trained Faster R-CNN model - 1 example"""

with open('/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/data_1.yaml', 'r') as f:

    data = f.read()

print(data)

# Define the label map according to the COCO dataset
label_map = {
    0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle',
    5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat',
    10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter',
    15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse',
    20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra',
    25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie',
    33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball',
    38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard',
    42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass',
    47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl',
    52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli',
    57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
    67: 'dining table', 70: 'toilet', 72: 'TV', 73: 'laptop', 74: 'mouse',
    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave',
    79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier',
    90: 'toothbrush'
}

import torch
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import functional as F
import numpy as np

# Set up the paths to the images and labels
train_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/train/images"
train_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/train/labels"

# Load the pre-trained Faster R-CNN model
model = fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Randomly select an image from the train_images directory
random_images = random.choice(os.listdir(train_images))

# Load an image
image_path = os.path.join(train_images, random_images)
image = Image.open(image_path).convert("RGB")

# Transform the image
image_tensor = F.to_tensor(image).unsqueeze(0)

# Move the image tensor and model to the device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
image_tensor = image_tensor.to(device)
model.to(device)

# Perform the prediction
with torch.no_grad():
    prediction = model(image_tensor)

# Visualization function
def show_prediction(img, pred):
    plt.figure(figsize=(12, 8))
    plt.imshow(img)
    ax = plt.gca()

    for element in range(len(pred[0]['boxes'])):
        boxes = pred[0]['boxes'][element].cpu().numpy()
        score = np.round(pred[0]['scores'][element].cpu().numpy(), decimals=4)
        label_id = int(pred[0]['labels'][element].cpu().numpy())  # Convert label_id to integer

        # Convert label ID to class name using the label map
        label_name = label_map.get(label_id, "Unknown")  # Default to 'Unknown' if label_id is not in label_map

        if score > 0.5:  # only show predictions with confidence above this threshold
            rect = plt.Rectangle((boxes[0], boxes[1]), boxes[2] - boxes[0], boxes[3] - boxes[1], fill=False, color='red', linewidth=2)
            ax.add_patch(rect)
            ax.text(boxes[0], boxes[1], f'{label_name}: {score}', va='bottom', color='white', backgroundcolor='red')

    plt.axis('off')
    plt.show()

# Example usage with an image and prediction

# Show the prediction
show_prediction(image, prediction)

"""# Try pre-trained Faster R-CNN model - 16 example"""

import cv2

# Set up the paths to the images and labels
train_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/train/images"

# Define your label map according to the COCO dataset
label_map = {
    0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle',
    5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat',
    10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter',
    15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse',
    20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra',
    25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie',
    33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball',
    38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard',
    42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass',
    47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl',
    52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli',
    57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
    67: 'dining table', 70: 'toilet', 72: 'TV', 73: 'laptop', 74: 'mouse',
    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave',
    79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier',
    90: 'toothbrush'
}

# Load the pre-trained Faster R-CNN model
model = fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()
model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

# Randomly select 16 images from the train_images directory
random_images = random.sample(os.listdir(train_images), 16)

# Create a subplot grid
fig, axs = plt.subplots(4, 4, figsize=(16, 12))

# Loop over the selected images and plot the object detections
for i, image_file in enumerate(random_images):
    row, col = divmod(i, 4)

    # Load and prepare the image
    image_path = os.path.join(train_images, image_file)
    image = Image.open(image_path).convert("RGB")
    image_tensor = F.to_tensor(image).unsqueeze(0).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

    # Perform the prediction
    with torch.no_grad():
        prediction = model(image_tensor)

    # Visualize the results
    boxes = prediction[0]['boxes'].cpu().numpy()
    scores = prediction[0]['scores'].cpu().numpy()
    labels = prediction[0]['labels'].cpu().numpy()
    img_np = np.array(image)

    for box, score, label in zip(boxes, scores, labels):
        if score > 0.5:
            label_name = label_map.get(label, "Unknown")
            cv2.rectangle(img_np, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 0, 255), 2)
            cv2.putText(img_np, f'{label_name}: {score:.2f}', (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)

    axs[row, col].imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
    axs[row, col].axis('off')

plt.show()

# Desired classes to display
desired_classes = {'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat'}

# Create a subplot grid
fig, axs = plt.subplots(4, 4, figsize=(16, 12))

# Loop over the selected images and plot the object detections
for i, image_file in enumerate(random_images):
    row, col = divmod(i, 4)

    # Load and prepare the image
    image_path = os.path.join(train_images, image_file)
    image = Image.open(image_path).convert("RGB")
    image_tensor = F.to_tensor(image).unsqueeze(0).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

    # Perform the prediction
    with torch.no_grad():
        prediction = model(image_tensor)

    # Visualize the results
    boxes = prediction[0]['boxes'].cpu().numpy()
    scores = prediction[0]['scores'].cpu().numpy()
    labels = prediction[0]['labels'].cpu().numpy()
    img_np = np.array(image)

    for box, score, label in zip(boxes, scores, labels):
        if score > 0.5:
            label_name = label_map.get(label, "Unknown")
            if label_name in desired_classes:
              cv2.rectangle(img_np, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 0, 255), 2)
              cv2.putText(img_np, f'{label_name}: {score:.2f}', (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)

    axs[row, col].imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
    axs[row, col].axis('off')

plt.show()

# Create a subplot grid
fig, axs = plt.subplots(4, 4, figsize=(16, 12))

# Process each image
for i, image_file in enumerate(random_images):
    row, col = divmod(i, 4)

    # Load and prepare the image
    image_path = os.path.join(train_images, image_file)
    image = Image.open(image_path).convert("RGB")
    image_tensor = F.to_tensor(image).unsqueeze(0).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

    # Perform the prediction
    with torch.no_grad():
        prediction = model(image_tensor)

    # Convert image for drawing
    img_np = np.array(image)
    classification_counts = {}

    # Draw detected objects and count classifications
    for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):
        if score > 0.5:
            label_name = label_map.get(label.item(), "Unknown")
            classification_counts[label_name] = classification_counts.get(label_name, 0) + 1
            cv2.rectangle(img_np, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 0, 255), 2)
            cv2.putText(img_np, f'{label_name}: {score:.2f}', (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)

    # Display the image
    axs[row, col].imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
    axs[row, col].axis('off')
    # Print the counts for each classification
    print(f"Counts for {image_file}: {classification_counts}")

plt.show()

"""#Validate model

Evaluate Precision & Recall & mAP50-95 for a random test
"""

# Define the label map according to the COCO dataset
COCO_map = {
    0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle',
    5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat',
    10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter',
    15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse',
    20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra',
    25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie',
    33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball',
    38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard',
    42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass',
    47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl',
    52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli',
    57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
    67: 'dining table', 70: 'toilet', 72: 'TV', 73: 'laptop', 74: 'mouse',
    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave',
    79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier',
    90: 'toothbrush'
}

traffic_map = {
    0: 'ambulance', 1: 'army vehicle', 2: 'auto rickshaw', 3: 'bicycle', 4: 'bus', 5: 'car',
    6: 'garbage van', 7: 'human hauler', 8: 'minibus', 9: 'minivan', 10: 'motorbike',
    11: 'pickup', 12: 'police car', 13: 'rickshaw', 14: 'scooter', 15: 'suv',
    16: 'taxi', 17: 'three wheelers (CNG)', 18: 'truck', 19: 'van', 20: 'wheelbarrow'
}

# Desired classes to display in COCO prediction
desired_classes = {'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat'}

import torch
import torchvision.transforms.functional as F
import numpy as np
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.patches as patches

def load_labels(label_file, image_width, image_height):
    """Load labels from a text file in YOLO format"""
    labels = []
    with open(label_file, 'r') as file:
        for line in file:
            parts = line.split()
            # Convert YOLO format to xmin, ymin, xmax, ymax
            x_center = float(parts[1]) * image_width
            y_center = float(parts[2]) * image_height
            width = float(parts[3]) * image_width
            height = float(parts[4]) * image_height
            xmin = x_center - width / 2
            ymin = y_center - height / 2
            xmax = x_center + width / 2
            ymax = y_center + height / 2

            label = {
                'class': int(parts[0]),
                'xmin': xmin,
                'ymin': ymin,
                'xmax': xmax,
                'ymax': ymax
            }
            labels.append(label)
    return labels

def convert_prediction(prediction):
    """Convert model prediction to a list of dictionaries"""
    pred_boxes = prediction[0]['boxes'].cpu().numpy()
    pred_scores = prediction[0]['scores'].cpu().numpy()
    pred_labels = prediction[0]['labels'].cpu().numpy()

    predictions_list = []
    for box, score, label in zip(pred_boxes, pred_scores, pred_labels):
        class_name = COCO_map[label] if label in COCO_map else str(label)
        if class_name in desired_classes:
            prediction_dict = {
                'box': box.tolist(),
                'score': score,
                'label': int(label)
            }
            predictions_list.append(prediction_dict)

    return predictions_list

def calculate_iou(boxA, boxB):
    """Calculate the Intersection over Union (IoU) of two bounding boxes."""
    # Extract coordinates from boxes
    boxA_xmin, boxA_ymin, boxA_xmax, boxA_ymax = boxA[0], boxA[1], boxA[2], boxA[3]
    boxB_xmin, boxB_ymin, boxB_xmax, boxB_ymax = boxB['xmin'], boxB['ymin'], boxB['xmax'], boxB['ymax']

    # determine the (x, y)-coordinates of the intersection rectangle
    xA = max(boxA_xmin, boxB_xmin)
    yA = max(boxA_ymin, boxB_ymin)
    xB = min(boxA_xmax, boxB_xmax)
    yB = min(boxA_ymax, boxB_ymax)

    # compute the area of intersection rectangle
    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)

    # compute the area of both the prediction and ground-truth rectangles
    boxAArea = (boxA_xmax - boxA_xmin + 1) * (boxA_ymax - boxA_ymin + 1)
    boxBArea = (boxB_xmax - boxB_xmin + 1) * (boxB_ymax - boxB_ymin + 1)

    # compute the intersection over union by taking the intersection area
    # and dividing it by the sum of prediction + ground-truth areas - the intersection area
    iou = interArea / float(boxAArea + boxBArea - interArea)

    # return the intersection over union value
    return iou

def calculate_ap(precision, recall):
    """Calculate Average Precision (AP) given precision and recall arrays."""
    # Append 0 and 1 to recall and precision arrays to ensure they start at 0 and end at 1
    recall = np.concatenate((np.array([0.]), recall, np.array([1.])))
    precision = np.concatenate((np.array([0.]), precision, np.array([0.])))

    # Compute the area under the precision-recall curve
    ap = np.trapz(precision, recall)

    return ap


def calculate_mAP(predictions, labels, label_map=None):
    """Calculate mean Average Precision (mAP) at different IoU thresholds (mAP50-95)."""
    # Initialize arrays to store precision and recall values at different IoU thresholds
    all_precisions = []
    all_recalls = []

    # Iterate over different IoU thresholds from 0.5 to 0.95 with a step size of 0.05
    iou_thresholds = np.arange(0.5, 1.0, 0.05)
    for threshold in iou_thresholds:
        # Calculate precision and recall for the current IoU threshold
        precision, recall = calculate_metrics(predictions, labels, threshold, label_map)
        all_precisions.append(precision)
        all_recalls.append(recall)

    # Calculate AP for each class
    ap_values = []
    for precision, recall in zip(all_precisions, all_recalls):
        # Ensure recall is an array
        recall = np.array([recall]) if isinstance(recall, float) else recall
        precision = np.array([precision]) if isinstance(precision, float) else precision

        # Append 0 and 1 to recall and precision arrays to ensure they start at 0 and end at 1
        recall = np.concatenate(([0.], recall, [1.]))
        precision = np.concatenate(([0.], precision, [0.]))

        # Compute the area under the precision-recall curve
        ap = np.trapz(precision, recall)
        ap_values.append(ap)

    # Calculate mean Average Precision (mAP) across all classes
    mAP = np.mean(ap_values)

    return mAP

def calculate_metrics(predictions, labels, threshold=0.5, label_map=None):
    """Calculate precision, recall, and mAP"""
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    all_ground_truth = len(labels)

    for pred in predictions:
        if pred['score'] >= threshold:
            found_match = False
            pred_class_name = COCO_map[pred['label']] if label_map is not None else str(pred['label'])
            for label in labels:
                true_class_name = traffic_map[label['class']] if label_map is not None else str(label['class'])
                if pred_class_name == true_class_name:
                    iou = calculate_iou(pred['box'], label)
                    if iou >= 0.5:
                        true_positives += 1
                        found_match = True
                        break
            if not found_match:
                false_positives += 1

    false_negatives = all_ground_truth - true_positives

    if true_positives + false_positives == 0:
        precision = np.array([0])  # Set precision to zero if both true positives and false positives are zero
    else:
        precision = np.array([true_positives / (true_positives + false_positives)])  # Convert to array

    if true_positives + false_negatives == 0:
        recall = np.array([0])  # Set recall to zero if both true positives and false negatives are zero
    else:
        recall = np.array([true_positives / (true_positives + false_negatives)])  # Convert to array

    return precision, recall

def visualize_comparison(image, predictions, labels, coco_map, traffic_map):
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Plot predicted bounding boxes
    axes[0].imshow(image)
    axes[0].set_title('Predicted')
    for pred in predictions:
        box = pred['box']
        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]
        width = xmax - xmin
        height = ymax - ymin
        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')
        axes[0].add_patch(rect)
        class_label = coco_map[pred['label']]
        axes[0].text(xmin, ymin, class_label, color='r', fontsize=8)

    # Plot corrected labeled bounding boxes
    axes[1].imshow(image)
    axes[1].set_title('Corrected Label')
    for label in labels:
        xmin, ymin, xmax, ymax = label['xmin'], label['ymin'], label['xmax'], label['ymax']
        width = xmax - xmin
        height = ymax - ymin
        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='g', facecolor='none')
        axes[1].add_patch(rect)
        class_label = traffic_map[label['class']]
        axes[1].text(xmin, ymin, class_label, color='g', fontsize=8)

    plt.show()

# Example usage

# Set paths
test_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/images"
test_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/labels"

# Load an image and its labels
random_image = random.choice(os.listdir(test_images))
image_path = os.path.join(test_images, random_image)
image = Image.open(image_path).convert("RGB")
label_path = os.path.join(test_labels, random_image.replace(".jpg", ".txt"))

# Get image dimensions
image_width, image_height = image.size

# Load labels
ground_truth = load_labels(label_path, image_width, image_height)

# Perform the prediction
image_tensor = F.to_tensor(image).unsqueeze(0)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
image_tensor = image_tensor.to(device)
model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)
model.eval()
with torch.no_grad():
    prediction = model(image_tensor)
    prediction = convert_prediction(prediction)

# Calculate metrics using traffic_map for labels
precision, recall = calculate_metrics(prediction, ground_truth, label_map=traffic_map)
mAP = calculate_mAP(prediction, ground_truth, label_map=traffic_map)
print("Precision:", precision)
print("Recall:", recall)
print("mAP50-95:", mAP)

# Visualize the predictions and corrected labeled bounding boxes with class labels
visualize_comparison(image, prediction, ground_truth, COCO_map, traffic_map)

"""Evaluate the test performance"""

import os
import random
import torch
import torchvision.transforms.functional as F
from PIL import Image
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from tqdm import tqdm

# Set paths
test_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/images"
test_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/labels"

# Initialize lists to store metrics
all_precisions = []
all_recalls = []
all_mAPs = []

# Iterate over all images in the test folder
num_images = len(os.listdir(test_images))
for image_name in tqdm(os.listdir(test_images), total=num_images):
    # Load image
    image_path = os.path.join(test_images, image_name)
    image = Image.open(image_path).convert("RGB")

    # Load labels
    label_path = os.path.join(test_labels, image_name.replace(".jpg", ".txt"))
    image_width, image_height = image.size
    ground_truth = load_labels(label_path, image_width, image_height)

    # Perform prediction
    image_tensor = F.to_tensor(image).unsqueeze(0)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    image_tensor = image_tensor.to(device)
    model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)
    model.eval()
    with torch.no_grad():
        prediction = model(image_tensor)
        prediction = convert_prediction(prediction)

    # Calculate metrics
    precision, recall = calculate_metrics(prediction, ground_truth, label_map=traffic_map)
    mAP = calculate_mAP(prediction, ground_truth, label_map=traffic_map)

    # Append metrics to lists
    all_precisions.append(precision)
    all_recalls.append(recall)
    all_mAPs.append(mAP)

# Compute mean metrics
mean_precision = sum(all_precisions) / len(all_precisions)
mean_recall = sum(all_recalls) / len(all_recalls)
mean_mAP = sum(all_mAPs) / len(all_mAPs)

print("Mean Precision:", mean_precision)
print("Mean Recall:", mean_recall)
print("Mean mAP50-95:", mean_mAP)

"""#Validate Faster-RCNN with changed real labels"""

# Define the label map according to the COCO dataset
COCO_map = {
    0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle',
    5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat',
    10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter',
    15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse',
    20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra',
    25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie',
    33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball',
    38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard',
    42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass',
    47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl',
    52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli',
    57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
    67: 'dining table', 70: 'toilet', 72: 'TV', 73: 'laptop', 74: 'mouse',
    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave',
    79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier',
    90: 'toothbrush'
}

# traffic_map = {
#     0: 'ambulance', 1: 'army vehicle', 2: 'auto rickshaw', 3: 'bicycle', 4: 'bus', 5: 'car',
#     6: 'garbage van', 7: 'human hauler', 8: 'minibus', 9: 'minivan', 10: 'motorbike',
#     11: 'pickup', 12: 'police car', 13: 'rickshaw', 14: 'scooter', 15: 'suv',
#     16: 'taxi', 17: 'three wheelers (CNG)', 18: 'truck', 19: 'van', 20: 'wheelbarrow'
# }

traffic_map_2 = {
    0: 'truck', 1: 'truck', 2: 'motorcycle', 3: 'bicycle', 4: 'bus', 5: 'car',
    6: 'truck', 7: 'human hauler', 8: 'bus', 9: 'truck', 10: 'motorcycle',
    11: 'truck', 12: 'car', 13: 'rickshaw', 14: 'scooter', 15: 'car',
    16: 'car', 17: 'three wheelers (CNG)', 18: 'truck', 19: 'truck', 20: 'wheelbarrow'
}

# Desired classes to display in COCO prediction
desired_classes = {'bicycle', 'car', 'motorcycle', 'bus', 'train', 'truck'}

import torch
import torchvision.transforms.functional as F
import numpy as np
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.patches as patches

def load_labels(label_file, image_width, image_height):
    """Load labels from a text file in YOLO format"""
    labels = []
    with open(label_file, 'r') as file:
        for line in file:
            parts = line.split()
            # Convert YOLO format to xmin, ymin, xmax, ymax
            x_center = float(parts[1]) * image_width
            y_center = float(parts[2]) * image_height
            width = float(parts[3]) * image_width
            height = float(parts[4]) * image_height
            xmin = x_center - width / 2
            ymin = y_center - height / 2
            xmax = x_center + width / 2
            ymax = y_center + height / 2

            label = {
                'class': int(parts[0]),
                'xmin': xmin,
                'ymin': ymin,
                'xmax': xmax,
                'ymax': ymax
            }
            labels.append(label)
    return labels

def convert_prediction(prediction):
    """Convert model prediction to a list of dictionaries"""
    pred_boxes = prediction[0]['boxes'].cpu().numpy()
    pred_scores = prediction[0]['scores'].cpu().numpy()
    pred_labels = prediction[0]['labels'].cpu().numpy()

    predictions_list = []
    for box, score, label in zip(pred_boxes, pred_scores, pred_labels):
        class_name = COCO_map[label] if label in COCO_map else str(label)
        if class_name in desired_classes:
            prediction_dict = {
                'box': box.tolist(),
                'score': score,
                'label': int(label)
            }
            predictions_list.append(prediction_dict)

    return predictions_list

def calculate_iou(boxA, boxB):
    """Calculate the Intersection over Union (IoU) of two bounding boxes."""
    # Extract coordinates from boxes
    boxA_xmin, boxA_ymin, boxA_xmax, boxA_ymax = boxA[0], boxA[1], boxA[2], boxA[3]
    boxB_xmin, boxB_ymin, boxB_xmax, boxB_ymax = boxB['xmin'], boxB['ymin'], boxB['xmax'], boxB['ymax']

    # determine the (x, y)-coordinates of the intersection rectangle
    xA = max(boxA_xmin, boxB_xmin)
    yA = max(boxA_ymin, boxB_ymin)
    xB = min(boxA_xmax, boxB_xmax)
    yB = min(boxA_ymax, boxB_ymax)

    # compute the area of intersection rectangle
    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)

    # compute the area of both the prediction and ground-truth rectangles
    boxAArea = (boxA_xmax - boxA_xmin + 1) * (boxA_ymax - boxA_ymin + 1)
    boxBArea = (boxB_xmax - boxB_xmin + 1) * (boxB_ymax - boxB_ymin + 1)

    # compute the intersection over union by taking the intersection area
    # and dividing it by the sum of prediction + ground-truth areas - the intersection area
    iou = interArea / float(boxAArea + boxBArea - interArea)

    # return the intersection over union value
    return iou

def calculate_ap(precision, recall):
    """Calculate Average Precision (AP) given precision and recall arrays."""
    # Append 0 and 1 to recall and precision arrays to ensure they start at 0 and end at 1
    recall = np.concatenate((np.array([0.]), recall, np.array([1.])))
    precision = np.concatenate((np.array([0.]), precision, np.array([0.])))

    # Compute the area under the precision-recall curve
    ap = np.trapz(precision, recall)

    return ap


def calculate_mAP(predictions, labels, label_map=None):
    """Calculate mean Average Precision (mAP) at different IoU thresholds (mAP50-95)."""
    # Initialize arrays to store precision and recall values at different IoU thresholds
    all_precisions = []
    all_recalls = []

    # Iterate over different IoU thresholds from 0.5 to 0.95 with a step size of 0.05
    iou_thresholds = np.arange(0.5, 1.0, 0.05)
    for threshold in iou_thresholds:
        # Calculate precision and recall for the current IoU threshold
        precision, recall = calculate_metrics(predictions, labels, threshold, label_map)
        all_precisions.append(precision)
        all_recalls.append(recall)

    # Calculate AP for each class
    ap_values = []
    for precision, recall in zip(all_precisions, all_recalls):
        # Ensure recall is an array
        recall = np.array([recall]) if isinstance(recall, float) else recall
        precision = np.array([precision]) if isinstance(precision, float) else precision

        # Append 0 and 1 to recall and precision arrays to ensure they start at 0 and end at 1
        recall = np.concatenate(([0.], recall, [1.]))
        precision = np.concatenate(([0.], precision, [0.]))

        # Compute the area under the precision-recall curve
        ap = np.trapz(precision, recall)
        ap_values.append(ap)

    # Calculate mean Average Precision (mAP) across all classes
    mAP = np.mean(ap_values)

    return mAP

def calculate_metrics(predictions, labels, threshold=0.5, label_map=None):
    """Calculate precision, recall, and mAP"""
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    all_ground_truth = len(labels)

    for pred in predictions:
        if pred['score'] >= threshold:
            found_match = False
            pred_class_name = COCO_map[pred['label']] if label_map is not None else str(pred['label'])
            for label in labels:
                true_class_name = traffic_map_2[label['class']] if label_map is not None else str(label['class'])
                if pred_class_name == true_class_name:
                    iou = calculate_iou(pred['box'], label)
                    if iou >= 0.5:
                        true_positives += 1
                        found_match = True
                        break
            if not found_match:
                false_positives += 1

    false_negatives = all_ground_truth - true_positives

    if true_positives + false_positives == 0:
        precision = np.array([0])  # Set precision to zero if both true positives and false positives are zero
    else:
        precision = np.array([true_positives / (true_positives + false_positives)])  # Convert to array

    if true_positives + false_negatives == 0:
        recall = np.array([0])  # Set recall to zero if both true positives and false negatives are zero
    else:
        recall = np.array([true_positives / (true_positives + false_negatives)])  # Convert to array

    return precision, recall

def visualize_comparison(image, predictions, labels, coco_map, traffic_map):
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Plot predicted bounding boxes
    axes[0].imshow(image)
    axes[0].set_title('Predicted')
    for pred in predictions:
        box = pred['box']
        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]
        width = xmax - xmin
        height = ymax - ymin
        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')
        axes[0].add_patch(rect)
        class_label = coco_map[pred['label']]
        axes[0].text(xmin, ymin, class_label, color='r', fontsize=8)

    # Plot corrected labeled bounding boxes
    axes[1].imshow(image)
    axes[1].set_title('Corrected Label')
    for label in labels:
        xmin, ymin, xmax, ymax = label['xmin'], label['ymin'], label['xmax'], label['ymax']
        width = xmax - xmin
        height = ymax - ymin
        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='g', facecolor='none')
        axes[1].add_patch(rect)
        class_label = traffic_map_2[label['class']]
        axes[1].text(xmin, ymin, class_label, color='g', fontsize=8)

    plt.show()

# Example usage

# Set paths
test_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/images"
test_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/labels"

# Load an image and its labels
random_image = random.choice(os.listdir(test_images))
image_path = os.path.join(test_images, random_image)
image = Image.open(image_path).convert("RGB")
label_path = os.path.join(test_labels, random_image.replace(".jpg", ".txt"))

# Get image dimensions
image_width, image_height = image.size

# Load labels
ground_truth = load_labels(label_path, image_width, image_height)

# Perform the prediction
image_tensor = F.to_tensor(image).unsqueeze(0)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
image_tensor = image_tensor.to(device)
model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)
model.eval()
with torch.no_grad():
    prediction = model(image_tensor)
    prediction = convert_prediction(prediction)

# Calculate metrics using traffic_map for labels
precision, recall = calculate_metrics(prediction, ground_truth, label_map=traffic_map_2)
mAP = calculate_mAP(prediction, ground_truth, label_map=traffic_map_2)
print("Precision:", precision)
print("Recall:", recall)
print("mAP50-95:", mAP)

# Visualize the predictions and corrected labeled bounding boxes with class labels
visualize_comparison(image, prediction, ground_truth, COCO_map, traffic_map_2)

import os
import random
import torch
import torchvision.transforms.functional as F
from PIL import Image
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from tqdm import tqdm

# Set paths
test_images = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/images"
test_labels = "/content/gdrive/My Drive/Colab Notebooks/CS543-project/trafic_data/test/labels"

# Initialize lists to store metrics
all_precisions = []
all_recalls = []
all_mAPs = []

# Iterate over all images in the test folder
num_images = len(os.listdir(test_images))
for image_name in tqdm(os.listdir(test_images), total=num_images):
    # Load image
    image_path = os.path.join(test_images, image_name)
    image = Image.open(image_path).convert("RGB")

    # Load labels
    label_path = os.path.join(test_labels, image_name.replace(".jpg", ".txt"))
    image_width, image_height = image.size
    ground_truth = load_labels(label_path, image_width, image_height)

    # Perform prediction
    image_tensor = F.to_tensor(image).unsqueeze(0)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    image_tensor = image_tensor.to(device)
    model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)
    model.eval()
    with torch.no_grad():
        prediction = model(image_tensor)
        prediction = convert_prediction(prediction)

    # Calculate metrics
    precision, recall = calculate_metrics(prediction, ground_truth, label_map=traffic_map)
    mAP = calculate_mAP(prediction, ground_truth, label_map=traffic_map)

    # Append metrics to lists
    all_precisions.append(precision)
    all_recalls.append(recall)
    all_mAPs.append(mAP)

# Compute mean metrics
mean_precision = sum(all_precisions) / len(all_precisions)
mean_recall = sum(all_recalls) / len(all_recalls)
mean_mAP = sum(all_mAPs) / len(all_mAPs)

print("Mean Precision:", mean_precision)
print("Mean Recall:", mean_recall)
print("Mean mAP50-95:", mean_mAP)